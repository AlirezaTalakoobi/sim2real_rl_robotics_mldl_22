{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_model run.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "BryR7lDsZRIH",
        "outputId": "d036b209-27de-4eb2-c7ee-1c5d3d80e4ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/machine learning 2022/project/ppo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.getcwd()\n",
        "os.chdir('./drive/MyDrive/machine learning 2022/project/ppo')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt-Zb7Rbjb37",
        "outputId": "15e5ca57-cd11-4785-fbbf-7ae1bd427d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ..\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKrTSfjopAtP",
        "outputId": "dbaf220e-0ca6-4a72-faef-75e4ad9bbe38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MLDL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/MLDL/TRPO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnpkmjKJjmYj",
        "outputId": "d1fb966d-3efe-4f27-8f55-809943df61df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/MLDL/TRPO'\n",
            "/content/drive/MyDrive/MLDL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd TRPO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yqBXLcWpGpN",
        "outputId": "e2afa191-f4d7-4064-d13b-f5fe77f0b2ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MLDL/TRPO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y \\\n",
        "    libgl1-mesa-dev \\\n",
        "    libgl1-mesa-glx \\\n",
        "    libglew-dev \\\n",
        "    libosmesa6-dev \\\n",
        "    software-properties-common\n",
        "\n",
        "!apt-get install -y patchelf\n",
        "\n",
        "!pip install gym\n",
        "!pip install free-mujoco-py\n",
        "!pip install tensorboard\n",
        "!pip install stable_baselines3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y0FwO0evbFMJ",
        "outputId": "1561fbeb-44fb-43d9-cf41-152723e6104c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libgl1-mesa-dev is already the newest version (20.0.8-0ubuntu1~18.04.1).\n",
            "libgl1-mesa-dev set to manually installed.\n",
            "software-properties-common is already the newest version (0.96.24.32.18).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  glew-utils\n",
            "The following NEW packages will be installed:\n",
            "  libgl1-mesa-glx libglew-dev libglew2.0 libosmesa6 libosmesa6-dev\n",
            "0 upgraded, 5 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 2,916 kB of archives.\n",
            "After this operation, 12.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgl1-mesa-glx amd64 20.0.8-0ubuntu1~18.04.1 [5,532 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libglew2.0 amd64 2.0.0-5 [140 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libglew-dev amd64 2.0.0-5 [120 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libosmesa6 amd64 20.0.8-0ubuntu1~18.04.1 [2,641 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libosmesa6-dev amd64 20.0.8-0ubuntu1~18.04.1 [8,828 B]\n",
            "Fetched 2,916 kB in 0s (9,263 kB/s)\n",
            "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
            "(Reading database ... 155632 files and directories currently installed.)\n",
            "Preparing to unpack .../libgl1-mesa-glx_20.0.8-0ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-glx:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Selecting previously unselected package libglew2.0:amd64.\n",
            "Preparing to unpack .../libglew2.0_2.0.0-5_amd64.deb ...\n",
            "Unpacking libglew2.0:amd64 (2.0.0-5) ...\n",
            "Selecting previously unselected package libglew-dev:amd64.\n",
            "Preparing to unpack .../libglew-dev_2.0.0-5_amd64.deb ...\n",
            "Unpacking libglew-dev:amd64 (2.0.0-5) ...\n",
            "Selecting previously unselected package libosmesa6:amd64.\n",
            "Preparing to unpack .../libosmesa6_20.0.8-0ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libosmesa6:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Selecting previously unselected package libosmesa6-dev:amd64.\n",
            "Preparing to unpack .../libosmesa6-dev_20.0.8-0ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libosmesa6-dev:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Setting up libosmesa6:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Setting up libgl1-mesa-glx:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Setting up libglew2.0:amd64 (2.0.0-5) ...\n",
            "Setting up libglew-dev:amd64 (2.0.0-5) ...\n",
            "Setting up libosmesa6-dev:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  patchelf\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 46.5 kB of archives.\n",
            "After this operation, 130 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 patchelf amd64 0.9-1 [46.5 kB]\n",
            "Fetched 46.5 kB in 0s (264 kB/s)\n",
            "Selecting previously unselected package patchelf.\n",
            "(Reading database ... 155670 files and directories currently installed.)\n",
            "Preparing to unpack .../patchelf_0.9-1_amd64.deb ...\n",
            "Unpacking patchelf (0.9-1) ...\n",
            "Setting up patchelf (0.9-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting free-mujoco-py\n",
            "  Downloading free_mujoco_py-2.1.6-py3-none-any.whl (14.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython<0.30.0,>=0.29.24 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py) (0.29.30)\n",
            "Collecting fasteners==0.15\n",
            "  Downloading fasteners-0.15-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: cffi<2.0.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py) (1.15.0)\n",
            "Collecting imageio<3.0.0,>=2.9.0\n",
            "  Downloading imageio-2.19.3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 48.8 MB/s \n",
            "\u001b[?25hCollecting glfw<2.0.0,>=1.4.0\n",
            "  Downloading glfw-1.12.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (203 kB)\n",
            "\u001b[K     |████████████████████████████████| 203 kB 72.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.21.3 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py) (1.21.6)\n",
            "Collecting monotonic>=0.1\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fasteners==0.15->free-mujoco-py) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi<2.0.0,>=1.15.0->free-mujoco-py) (2.21)\n",
            "Collecting pillow>=8.3.2\n",
            "  Downloading Pillow-9.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 48.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow, monotonic, imageio, glfw, fasteners, free-mujoco-py\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed fasteners-0.15 free-mujoco-py-2.1.6 glfw-1.12.0 imageio-2.19.3 monotonic-1.6 pillow-9.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.46.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-1.5.0-py3-none-any.whl (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.11.0+cu113)\n",
            "Collecting gym==0.21\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 66.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.3.5)\n",
            "Requirement already satisfied: importlib_metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym==0.21->stable_baselines3) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable_baselines3) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable_baselines3) (4.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (1.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->stable_baselines3) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable_baselines3) (2022.1)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616827 sha256=7d52a19f5d07062a59d495abe585dc35f873d1aabd8db264ff504d356e2bd2c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/ee/9c/36bfe3e079df99acf5ae57f4e3464ff2771b34447d6d2f2148\n",
            "Successfully built gym\n",
            "Installing collected packages: gym, stable-baselines3\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "Successfully installed gym-0.21.0 stable-baselines3-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd TRPO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeEpu8wkweQX",
        "outputId": "f56f7796-57bd-437a-c8f5-fd7b9e7465b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MLDL/TRPO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --n-timesteps 100000 --device cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTzlqGvVZeV6",
        "outputId": "d5d60876-7b5d-4c9b-9d43-2f644756f7ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action space: Box([-1. -1. -1.], [1. 1. 1.], (3,), float32)\n",
            "State space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf], (11,), float64)\n",
            "Dynamics parameters: [2.53429174 3.92699082 2.71433605 5.0893801 ]\n",
            "Num timesteps: 1000\n",
            "Best mean reward: -inf - Last mean reward per episode: 18.26\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 2000\n",
            "Best mean reward: 18.26 - Last mean reward per episode: 15.71\n",
            "Num timesteps: 3000\n",
            "Best mean reward: 18.26 - Last mean reward per episode: 17.74\n",
            "Num timesteps: 4000\n",
            "Best mean reward: 18.26 - Last mean reward per episode: 24.37\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 5000\n",
            "Best mean reward: 24.37 - Last mean reward per episode: 35.91\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 6000\n",
            "Best mean reward: 35.91 - Last mean reward per episode: 46.59\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 7000\n",
            "Best mean reward: 46.59 - Last mean reward per episode: 59.62\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 8000\n",
            "Best mean reward: 59.62 - Last mean reward per episode: 73.34\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 9000\n",
            "Best mean reward: 73.34 - Last mean reward per episode: 84.78\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 10000\n",
            "Best mean reward: 84.78 - Last mean reward per episode: 97.15\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 11000\n",
            "Best mean reward: 97.15 - Last mean reward per episode: 106.12\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 12000\n",
            "Best mean reward: 106.12 - Last mean reward per episode: 118.53\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 13000\n",
            "Best mean reward: 118.53 - Last mean reward per episode: 129.31\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 14000\n",
            "Best mean reward: 129.31 - Last mean reward per episode: 140.47\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 15000\n",
            "Best mean reward: 140.47 - Last mean reward per episode: 149.60\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 16000\n",
            "Best mean reward: 149.60 - Last mean reward per episode: 160.71\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 17000\n",
            "Best mean reward: 160.71 - Last mean reward per episode: 173.26\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 18000\n",
            "Best mean reward: 173.26 - Last mean reward per episode: 180.79\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 19000\n",
            "Best mean reward: 180.79 - Last mean reward per episode: 190.57\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 20000\n",
            "Best mean reward: 190.57 - Last mean reward per episode: 203.72\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 21000\n",
            "Best mean reward: 203.72 - Last mean reward per episode: 218.43\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 22000\n",
            "Best mean reward: 218.43 - Last mean reward per episode: 227.56\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 23000\n",
            "Best mean reward: 227.56 - Last mean reward per episode: 231.03\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 24000\n",
            "Best mean reward: 231.03 - Last mean reward per episode: 240.04\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 25000\n",
            "Best mean reward: 240.04 - Last mean reward per episode: 247.96\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 26000\n",
            "Best mean reward: 247.96 - Last mean reward per episode: 256.76\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 27000\n",
            "Best mean reward: 256.76 - Last mean reward per episode: 260.59\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 28000\n",
            "Best mean reward: 260.59 - Last mean reward per episode: 267.13\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 29000\n",
            "Best mean reward: 267.13 - Last mean reward per episode: 272.84\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 30000\n",
            "Best mean reward: 272.84 - Last mean reward per episode: 279.67\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 31000\n",
            "Best mean reward: 279.67 - Last mean reward per episode: 287.12\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 32000\n",
            "Best mean reward: 287.12 - Last mean reward per episode: 291.55\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 33000\n",
            "Best mean reward: 291.55 - Last mean reward per episode: 295.76\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 34000\n",
            "Best mean reward: 295.76 - Last mean reward per episode: 297.30\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 35000\n",
            "Best mean reward: 297.30 - Last mean reward per episode: 300.20\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 36000\n",
            "Best mean reward: 300.20 - Last mean reward per episode: 303.60\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 37000\n",
            "Best mean reward: 303.60 - Last mean reward per episode: 305.59\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 38000\n",
            "Best mean reward: 305.59 - Last mean reward per episode: 310.67\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 39000\n",
            "Best mean reward: 310.67 - Last mean reward per episode: 318.86\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 40000\n",
            "Best mean reward: 318.86 - Last mean reward per episode: 323.37\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 41000\n",
            "Best mean reward: 323.37 - Last mean reward per episode: 331.53\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 42000\n",
            "Best mean reward: 331.53 - Last mean reward per episode: 334.32\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 43000\n",
            "Best mean reward: 334.32 - Last mean reward per episode: 337.84\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 44000\n",
            "Best mean reward: 337.84 - Last mean reward per episode: 344.65\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 45000\n",
            "Best mean reward: 344.65 - Last mean reward per episode: 349.84\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 46000\n",
            "Best mean reward: 349.84 - Last mean reward per episode: 353.60\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 47000\n",
            "Best mean reward: 353.60 - Last mean reward per episode: 357.07\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 48000\n",
            "Best mean reward: 357.07 - Last mean reward per episode: 362.55\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 49000\n",
            "Best mean reward: 362.55 - Last mean reward per episode: 368.18\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 50000\n",
            "Best mean reward: 368.18 - Last mean reward per episode: 379.12\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 51000\n",
            "Best mean reward: 379.12 - Last mean reward per episode: 390.48\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 52000\n",
            "Best mean reward: 390.48 - Last mean reward per episode: 401.83\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 53000\n",
            "Best mean reward: 401.83 - Last mean reward per episode: 413.67\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 54000\n",
            "Best mean reward: 413.67 - Last mean reward per episode: 425.84\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 55000\n",
            "Best mean reward: 425.84 - Last mean reward per episode: 441.12\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 56000\n",
            "Best mean reward: 441.12 - Last mean reward per episode: 455.69\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 57000\n",
            "Best mean reward: 455.69 - Last mean reward per episode: 459.63\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 58000\n",
            "Best mean reward: 459.63 - Last mean reward per episode: 475.10\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 59000\n",
            "Best mean reward: 475.10 - Last mean reward per episode: 487.86\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 60000\n",
            "Best mean reward: 487.86 - Last mean reward per episode: 498.45\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 61000\n",
            "Best mean reward: 498.45 - Last mean reward per episode: 513.28\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 62000\n",
            "Best mean reward: 513.28 - Last mean reward per episode: 535.71\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 63000\n",
            "Best mean reward: 535.71 - Last mean reward per episode: 549.32\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 64000\n",
            "Best mean reward: 549.32 - Last mean reward per episode: 562.47\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 65000\n",
            "Best mean reward: 562.47 - Last mean reward per episode: 570.38\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 66000\n",
            "Best mean reward: 570.38 - Last mean reward per episode: 584.23\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 67000\n",
            "Best mean reward: 584.23 - Last mean reward per episode: 606.50\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 68000\n",
            "Best mean reward: 606.50 - Last mean reward per episode: 623.84\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 69000\n",
            "Best mean reward: 623.84 - Last mean reward per episode: 637.17\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 70000\n",
            "Best mean reward: 637.17 - Last mean reward per episode: 653.73\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 71000\n",
            "Best mean reward: 653.73 - Last mean reward per episode: 669.72\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 72000\n",
            "Best mean reward: 669.72 - Last mean reward per episode: 682.78\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 73000\n",
            "Best mean reward: 682.78 - Last mean reward per episode: 693.87\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 74000\n",
            "Best mean reward: 693.87 - Last mean reward per episode: 703.69\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 75000\n",
            "Best mean reward: 703.69 - Last mean reward per episode: 717.62\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 76000\n",
            "Best mean reward: 717.62 - Last mean reward per episode: 730.94\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 77000\n",
            "Best mean reward: 730.94 - Last mean reward per episode: 742.68\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 78000\n",
            "Best mean reward: 742.68 - Last mean reward per episode: 749.25\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 79000\n",
            "Best mean reward: 749.25 - Last mean reward per episode: 741.05\n",
            "Num timesteps: 80000\n",
            "Best mean reward: 749.25 - Last mean reward per episode: 742.50\n",
            "Num timesteps: 81000\n",
            "Best mean reward: 749.25 - Last mean reward per episode: 746.81\n",
            "Num timesteps: 82000\n",
            "Best mean reward: 749.25 - Last mean reward per episode: 750.94\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 83000\n",
            "Best mean reward: 750.94 - Last mean reward per episode: 764.03\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 84000\n",
            "Best mean reward: 764.03 - Last mean reward per episode: 769.48\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 85000\n",
            "Best mean reward: 769.48 - Last mean reward per episode: 780.69\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 86000\n",
            "Best mean reward: 780.69 - Last mean reward per episode: 779.29\n",
            "Num timesteps: 87000\n",
            "Best mean reward: 780.69 - Last mean reward per episode: 780.50\n",
            "Num timesteps: 88000\n",
            "Best mean reward: 780.69 - Last mean reward per episode: 779.43\n",
            "Num timesteps: 89000\n",
            "Best mean reward: 780.69 - Last mean reward per episode: 778.03\n",
            "Num timesteps: 90000\n",
            "Best mean reward: 780.69 - Last mean reward per episode: 779.64\n",
            "Num timesteps: 91000\n",
            "Best mean reward: 780.69 - Last mean reward per episode: 782.12\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 92000\n",
            "Best mean reward: 782.12 - Last mean reward per episode: 772.03\n",
            "Num timesteps: 93000\n",
            "Best mean reward: 782.12 - Last mean reward per episode: 767.28\n",
            "Num timesteps: 94000\n",
            "Best mean reward: 782.12 - Last mean reward per episode: 763.37\n",
            "Num timesteps: 95000\n",
            "Best mean reward: 782.12 - Last mean reward per episode: 772.38\n",
            "Num timesteps: 96000\n",
            "Best mean reward: 782.12 - Last mean reward per episode: 775.72\n",
            "Num timesteps: 97000\n",
            "Best mean reward: 782.12 - Last mean reward per episode: 776.16\n",
            "Num timesteps: 98000\n",
            "Best mean reward: 782.12 - Last mean reward per episode: 789.52\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 99000\n",
            "Best mean reward: 789.52 - Last mean reward per episode: 798.16\n",
            "Saving new best model to best_model\n",
            "Num timesteps: 100000\n",
            "Best mean reward: 798.16 - Last mean reward per episode: 806.07\n",
            "Saving new best model to best_model\n",
            "saved\n",
            "<Figure size 800x200 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --model ./model.mdl"
      ],
      "metadata": {
        "id": "y1HELc5pfnCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c3fcddb-b1e9-4f2e-fd53-b74c56be2ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action space: Box([-1. -1. -1.], [1. 1. 1.], (3,), float32)\n",
            "State space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf], (11,), float64)\n",
            "Dynamics parameters: [3.53429174 3.92699082 2.71433605 5.0893801 ]\n",
            "reward at epsiode 1 is: 1056.6779366482176\n",
            "reward at epsiode 2 is: 1099.3182061431157\n",
            "reward at epsiode 3 is: 1108.8220197351854\n",
            "reward at epsiode 4 is: 1083.1388120253075\n",
            "reward at epsiode 5 is: 1058.6479229839556\n",
            "reward at epsiode 6 is: 1073.579744124238\n",
            "reward at epsiode 7 is: 1064.7070125794307\n",
            "reward at epsiode 8 is: 1053.9277449224633\n",
            "reward at epsiode 9 is: 1082.5297440499492\n",
            "reward at epsiode 10 is: 1078.5281660737598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3_8Hl5ytgoMb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}